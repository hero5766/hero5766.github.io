---
title: 三维视觉
author: hero576
tags:
  - robotic
categories:
  - programme
date: 2020-10-09 10:57:07
---
> 
<!--more-->

# 简介
## 介绍
- 三维视觉相较于二维视觉增加了深度信息，可以更好的利用环境信息，为物体分类、目标检测、场景分割等任务提供更多的信息。

## 三维表达
- 三维表达的方法

三维表达|说明
-|-
point cloud|点云
mesh|三角形或三变形面片组合
volumetric|栅格化
projected view RGB(D)|图片拼接，具有RGB信息


## 数据集

形状分类的数据集|samples|classes|type|representation
-|-|-|-|-
McGill Benchmark|456|19|Synthetic|Mesh
Sydney Urban Objects|588|14|Real-World|point cloud
ModelNet10|4899|10|Synthetic|Mesh
ModelNet40|12311|40|Synthetic|Mesh
ShapeNet|51190|55|Synthetic|Mesh
ScanNet|12283|17|Real-World|RGB-D
ScanObjectNN|2902|15|Real-World|point cloud

目标检测和跟踪数据集|scenes|classes|type|representation
-|-|-|-|-
KITTI|22|8|Urban(driving)|RGB&LiDAR
SUN RGB-D|47|37|Indoor|RGBD
ScanNetV2|1.5K|18|Indoor|RGBD&Mesh
H3D|160|8|Urban(driving)|RGB&LiDAR
Argoverse|113|15|Urban(driving)|RGB&LiDAR
Lyft L5|366|9|Urban(driving)|RGB&LiDAR
A*3D|-|7|Urban(driving)|RGB&LiDAR
Waymo Open|1K|4|Urban(driving)|RGB&LiDAR
nuScenes|1K|23|Urban(driving)|RGB&LiDAR

3d点云分割数据集|points|classes|RGB|sensors
-|-|-|-|-
Oakland|1.6M|5(44)|N/A|MLS
ISPRS|1.2M|9|N/A|ALS
Paris-rue-Madame|20M|17|N/A|MLS
IQmulus|300M|8(22)|N/A|MLS
ScanNet|-|20(20)|Yes|RGBD
S3DIS|273M|13(13)|Yes|Matterport
Semantic3D|4000M|8(9)|Yes|TLS
Paris-Lile-3D|143M|9(50)|N/A|MLS
SemanticKITTI|4549M|25(28)|N/A|MLS
Toronto-3D|78.3M|8(9)|Yes|MLS
DALES|505M|8(9)|N/A|ALS

## 点云数据的特征
- 采集数据近密远疏
- 非结构化
- 点云的无序性

## 处理的方法
- 基于结构化网格
  - Voxel based：体素化
  - multiview based：多视角投影为二维图处理

- 点云直接处理
![深度学习处理方法](/images/pasted-286.png)
![深度学习处理方法](/images/pasted-287.png)

- 基于图的方法

# 常见算法
## PointNet
- [PointNet](https://arxiv.org/pdf/1612.00593.pdf)，2016。直接使用点云数据进行分类、分割的目标。

- 之前处理点云的方法
  - 可以栅格化后，通过3D-CNN处理，例如VoxNet算法；
  - 通过投影，得到图像，通过2D-CNN识别，例如Multi-view CNN
  - 抽取特征，通过全连接网络处理

- PointNet就直接利用点云数据进行处理，实现分类、分割等操作。
- 利用点云，模型会遇到两个挑战：
  - 模型顺序无关性
  - 模型几何不变性


### 模型顺序无关性
- 对称函数满足顺序无关，例如：max()、sum()等函数。
- 神经网络中$f(x1,...,x_n)=\gamma g(h(x_1),...,h(x_n))$的复合函数，共享的h(x)函数使用MLP将输入转换为高维向量，减少后续g(x)池化的维度丢失的问题

![复合函数](/images/pasted-288.png)

- 作者证明：PointNet可以拟合任意的连续函数

### 模型几何不变性
- 引入变换网络，通过矩阵乘法，使得模型可以自动找到旋转的角度，适应目标的识别。

![旋转匹配函数](/images/pasted-289.png)

- 其中T-Net可以用mlp实现。

### 整体模型

![分类检测](/images/pasted-290.png)

- 在目标分割时，全局特征已经不具有每个点的信息了，所以与maxpool前的数据进行了特征的拼接，再经过MLP，得到每个点的分类得分。
![目标分割](/images/pasted-291.png)


## PointNet++

- [PointNet++](https://arxiv.org/abs/1706.02413)2017，PointNet没有局部区域的关注，PointNet++借鉴了CNN的思想，通过串联的多级别的感受野，多层次特征提取结构提升模型性能，同时保证旋转不变性和顺序无关性。


### 改进
- 整体流程：
  - sampling centroid抽样：在点云中首先通过centroid中心点
  - group points by centroid组类别选取：在centroid周围的点组成一个组，多个centroid将点集划分为重叠的局部区域。
  - pointnet on each group：对每个组进行pointnet识别，此时通过多个局部信息的学习，模型就具有了上下文的信息了

![点集](/images/pasted-295.png)

- 与CNN相似，提取局部特征以捕获来自小邻域的精细几何结构。这些局部特征将进一步分组为较大的单元，并进行处理以生成更高级别的特征。重复此过程，直到获得整个点集的特征为止。


### 结构图
![结构图](/images/pasted-296.png)

### 采样的方法
- uniform sampling：均匀采样
- farthest sampling：最远点采样，可以更好的覆盖采样空间。类似于kmeans++初始点选取
  > input points$[x_1,x_2,...,x_n]$, we use iterative FPS to choose a subset of points$[x_{i_1},x_{i_2},...,x_{i_m}]$, such that $x_{i_j}$ is the most distant point(in metric distance) from the set$[x_{i_1},x_{i_2},...,x_{i_{j-1}}]$ with regard to the rest points. 
  
### 分组方法
- K nearest neighbors：KNN算法
- Ball query：球查询的方法
  - 查找点求半径范围所有点，可以保证固定区域尺寸，是区域特征更具通用性

### 插值方法
- 在分割时，由于点云的稀疏，需要进行Feature Porpagation进行插值，插值方法基于距离权重的倒数平均，基于KNN(p=2,k=3)
- $f^{(j)}(x)=\frac{\sum_{i=1}^{k}{w_i(x)f_{i}^{(j)}}}{\sum_{i=1}^{k}{w_i(x)}},\; where\; w_i(x)=\frac{1}{d(x,x_i)^p},j=1,...,C$


### 非均匀点云数据优化
- 由于点云数据的近密远疏，噪声的非均匀点云对于PointNet++非层次话的学习有很大的影响，PointNet++使用MRG方法，增加多尺度信息
  - Multi-scale grouping(MSG)：多尺度的拼接，拼接多个视野的特征点，数量级较大
  - Multi-resolution grouping(MRG)：多层次的凭借，分层拼接
  - Single scale grouping (SSG)

![非均匀点云的处理](/images/pasted-297.png)



