---
title: ç¥ç»ç½‘ç»œ
author: hero576
tags:
  - algorithm
categories:
  - AI
date: 2020-08-21 10:41:00
---
> ç¥ç»ç½‘ç»œç®—æ³•

<!--more-->

# æ„ŸçŸ¥æœºï¼ˆPerceptronï¼‰

## ç¥ç»å…ƒï¼ˆneuronï¼‰æ¨¡å‹
- è”ç»“ä¸»ä¹‰ï¼šç¥ç»ç½‘ç»œæ˜¯ç”±å…·æœ‰é€‚åº”æ€§çš„ç®€å•å•å…ƒç»„æˆçš„å¹¿æ³›å¹¶è¡Œäº’è¿çš„ç½‘ç»œï¼Œå®ƒçš„ç»„ç»‡èƒ½å¤Ÿæ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»ç³»ç»Ÿå¯¹çœŸå®ä¸–ç•Œç‰©ä½“æ‰€ä½œå‡ºçš„äº¤äº’ååº”ã€‚
- ç¥ç»ç½‘ç»œä¸­æœ€åŸºæœ¬çš„æˆåˆ†æ˜¯ç¥ç»å…ƒï¼ˆneuronï¼‰æ¨¡å‹ï¼Œå³â€œç®€å•å•å…ƒâ€ï¼Œåœ¨ç”Ÿç‰©ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸ªç¥ç»å…ƒä¸å…¶ä»–ç¥ç»å…ƒç›¸è¿ï¼Œå½“å®ƒâ€œå…´å¥‹â€æ—¶ï¼Œå°±ä¼šå‘ç›¸è¿çš„ç¥ç»å…ƒå‘é€åŒ–å­¦ç‰©è´¨ï¼Œä»è€Œæ”¹å˜è¿™äº›ç¥ç»å…ƒå†…çš„ç”µä½ï¼›å¦‚æœæŸç¥ç»å…ƒçš„ç”µä½è¶…è¿‡ä¸€ä¸ªâ€œé˜ˆå€¼ï¼ˆthresholdï¼‰â€ï¼Œé‚£ä¹ˆå®ƒå°±ä¼šè¢«æ¿€æ´»ï¼Œå³â€œå…´å¥‹â€ èµ·æ¥ï¼Œå‘å…¶ä»–ç¥ç»å…ƒå‘é€åŒ–å­¦ç‰©è´¨ã€‚

![ç¥ç»å…ƒ](/images/pasted-92.png)

## æ„ŸçŸ¥æœºæ¨¡å‹
- æ„ŸçŸ¥æœºç”±å•ä¸ªç¥ç»å…ƒç»„æˆçš„å•å±‚ç¥ç»ç½‘ç»œï¼Œæ ‘çªæ¥æ”¶å…¶ä»–è½´çªä¼ é€’æ¥çš„ä¿¡æ¯ï¼Œåœ¨é€šè¿‡è‡ªå·±çš„è½´çªä¼ é€’å‡ºå»ã€‚æ„ŸçŸ¥æœºä¸‰ä¸ªåŠŸèƒ½ï¼šåŠ æƒã€æ±‚å’Œã€æ¿€åŠ±

![æ„ŸçŸ¥æœº](/images/pasted-94.png)

- æƒé‡åŠé˜ˆå€¼Î¸é€šè¿‡å­¦ä¹ è·å¾—ï¼Œé˜ˆå€¼Î¸å¯çœ‹åšä¸€ä¸ªå›ºå®šè¾“å…¥ä¸º-1çš„å“‘ç»“ç‚¹ï¼ˆdummy nodeï¼‰æ‰€å¯¹åº”çš„æƒé‡ ã€‚è¿™æ ·æƒé‡å’Œé˜ˆå€¼å¯ä»¥ç»Ÿä¸€å­¦ä¹ ã€‚å¯¹è®­ç»ƒæ ·ä¾‹(x,y)ï¼Œæ„ŸçŸ¥æœºè¾“å‡º ï¼Œå­¦ä¹ è§„åˆ™ï¼š$w_iâ†w_i+\nabla{w_i}$ $\nabla{w_i}=Î·(y-\widehat{y})x_i$
- Î·âˆˆ(0,1)ç§°ä¸ºå­¦ä¹ ç‡(learning rate)ã€‚

## å¯¹å¶å½¢å¼
- æ¯ä¸€è½®è¿­ä»£ä¸­æˆ‘ä»¬éƒ½è¦åˆ¤æ–­æŸä¸ªè¾“å…¥å®ä¾‹æ˜¯ä¸æ˜¯è¯¯åˆ¤ç‚¹ï¼Œå³$y_i(wx_i+b)<=0$åˆ™ä¸ºè¯¯åˆ¤ï¼Œéœ€è¦æ›´æ–°æƒé‡ã€‚æ—¶é—´å¤æ‚åº¦O(n)ï¼Œnä¸ºç‰¹å¾æ•°é‡ã€‚
- ä½¿ç”¨å¯¹å¶å½¢å¼ï¼Œåˆ¤æ–­æ¡ä»¶æ”¹ä¸ºï¼š$y_i(\sum_{j=1}^{N}a_jy_jx_jx_i+b)$ï¼Œé¢„å…ˆè®¡ç®—è¾“å…¥å®ä¾‹ä¸¤ä¸¤å†…ç§¯ï¼Œå¾—åˆ°GramçŸ©é˜µ$G=[x_ix_j]_{N*N}$ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(N)ï¼ŒNä¸ºè®­ç»ƒæ•°æ®æ•°é‡ã€‚
- å¯¹å¶å½¢å¼çš„ç›®çš„æ˜¯é™ä½è¿ç®—é‡ï¼Œä½†æ˜¯å¹¶ä¸æ˜¯åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½èƒ½é™ä½è¿ç®—é‡ï¼Œè€Œæ˜¯åœ¨ç‰¹å¾ç©ºé—´çš„ç»´åº¦å¾ˆé«˜æ—¶æ‰èµ·åˆ°ä½œç”¨ã€‚

## æ„ŸçŸ¥æœºçš„é—®é¢˜
- æ„ŸçŸ¥æœºåªæœ‰è¾“å‡ºå±‚ç¥ç»å…ƒè¿›è¡Œæ¿€æ´»å‡½æ•°å¤„ç†ï¼Œå³åªæ‹¥æœ‰ä¸€å±‚åŠŸèƒ½ç¥ç»å…ƒã€‚ä¸æˆ–éé—®é¢˜éƒ½æ˜¯çº¿æ€§å¯åˆ†ï¼ˆlinearly separableï¼‰ã€‚æ„ŸçŸ¥æœºå¯¹çº¿æ€§å¯åˆ†å­¦ä¹ è¿‡ç¨‹ä¸€å®šæ”¶æ•›ï¼Œéçº¿æ€§å¯åˆ†é—®é¢˜wéš¾ä»¥ç¨³å®šä¸‹æ¥ï¼Œä¸èƒ½æ±‚åˆé€‚çš„è§£ï¼Œå¦‚ä¸‹å›¾ã€‚

![æ„ŸçŸ¥æœºæ— æ³•è§£å†³éçº¿æ€§é—®é¢˜](/images/pasted-95.png)

- è¦è§£å†³éçº¿æ€§å¯åˆ†é—®é¢˜ï¼Œéœ€è¦è€ƒè™‘ä½¿ç”¨å¤šå±‚åŠŸèƒ½ç¥ç»å…ƒ

![èƒ½è§£å†³éçº¿æ€§é—®é¢˜çš„ä¸¤å±‚æ„ŸçŸ¥æœº](/images/pasted-96.png)

# å¤šå±‚æ„ŸçŸ¥æœº
## å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹

![å¤šå±‚æ„ŸçŸ¥æœº](/images/pasted-97.png)

### ç½‘ç»œç»“æ„
- è¾“å…¥å±‚ï¼š$x_i(i=0,...d)$
- éšè—å±‚ï¼šéšè—å•å…ƒ$z_h(h=1,...H)$ï¼Œåªæœ‰ä¸€ä¸ªéšè—å±‚æ—¶ï¼Œç½‘ç»œæ˜¯ä¸¤å±‚ç½‘ç»œã€‚
- è¾“å‡ºå±‚ï¼š$y_i(i=0,...K)$

- å¤šå±‚æ„ŸçŸ¥æœºå±‚ä¸å±‚ä¹‹é—´æ˜¯å…¨è¿æ¥çš„

- ç½‘ç»œç»“æ„ä¸­ï¼Œè¾“å…¥å±‚ä¸è¾“å‡ºå±‚ä¹‹é—´çš„ç¥ç»å…ƒå±‚æˆä¸ºéšå«å±‚ï¼ˆhidden layerï¼‰ï¼Œæ¯å±‚ç¥ç»å…ƒä¸ä¸‹ä¸€å±‚ç¥ç»å…ƒå®Œå…¨äº’è”ï¼Œç¥ç»å…ƒä¹‹é—´ä¸å­˜åœ¨åŒå±‚è¿æ¥ï¼Œä¹Ÿä¸å­˜åœ¨è·¨å±‚è¿æ¥ï¼Œç§°ä¸º**å¤šå±‚å‰é¦ˆç½‘ç»œç»“æ„**(multi-layer feedforward nerual networks)
  - å¤šå±‚ç½‘ç»œï¼šåŒ…å«éšå±‚çš„ç½‘ç»œ
  - å‰é¦ˆç½‘ç»œï¼šç¥ç»å…ƒä¹‹é—´ä¸å­˜åœ¨åŒå±‚è¿æ¥ä¹Ÿä¸å­˜åœ¨è·¨å±‚è¿æ¥  

- éšå±‚å’Œè¾“å‡ºå±‚å…·æœ‰æ¿€æ´»å‡½æ•°ï¼Œæ‰€ä»¥è¿™ä¸¤å±‚çš„ç¥ç»å…ƒäº¦ç§°â€œåŠŸèƒ½å•å…ƒâ€ã€‚å¤šå±‚å‰é¦ˆç½‘ç»œæœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚åªéœ€ä¸€ä¸ªåŒ…å«è¶³å¤Ÿå¤šç¥ç»å…ƒçš„éšå±‚ï¼Œå¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œå°±èƒ½ä»¥ä»»æ„ç²¾åº¦é€¼è¿‘ä»»æ„å¤æ‚åº¦çš„è¿ç»­å‡½æ•°ã€‚è®¾ç½®éšå±‚ç¥ç»å…ƒæ•°ï¼Œé€šå¸¸ç”¨â€œè¯•é”™æ³•â€ã€‚
  - ä¸»è¦ç‰¹ç‚¹ï¼šä¿¡å·æ˜¯å‰å‘ä¼ æ’­çš„ï¼Œè€Œè¯¯å·®æ˜¯åå‘ä¼ æ’­çš„ã€‚
  - ä¸»è¦è¿‡ç¨‹ï¼šä¿¡å·çš„å‰å‘ä¼ æ’­ï¼Œä»è¾“å…¥å±‚ç»è¿‡éšå«å±‚ï¼Œæœ€ååˆ°è¾¾è¾“å‡ºå±‚
  - è¯¯å·®çš„åå‘ä¼ æ’­ï¼Œä»è¾“å‡ºå±‚åˆ°éšå«å±‚ï¼Œæœ€ååˆ°è¾“å…¥å±‚ï¼Œä¾æ¬¡è°ƒèŠ‚éšå«å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡å’Œåç½®ï¼Œè¾“å…¥å±‚åˆ°éšå«å±‚çš„æƒé‡å’Œåç½®

## å…¨è¿æ¥å±‚

![å…¨è¿æ¥å±‚](/images/pasted-105.png)

### å‰å‘è¿ç®—
- æ”¾å°„å˜æ¢ï¼š$Y=X \cdot W +B$
- $X=(x_0,...x_n)$

### åå‘è¿ç®—
- Jæ˜¯ä»£ä»·å‡½æ•°
- $\frac{\partial J}{\partial X}=(\frac{\partial J}{\partial x_0}...)$
- $\frac{\partial J}{\partial X}=\frac{\partial J}{\partial Y}\cdot W^T$
- $\frac{\partial J}{\partial W}=X^T\cdot\frac{\partial J}{\partial Y}$


## æ¿€æ´»å‡½æ•°
- éšå±‚ä¸€èˆ¬ä½¿ç”¨sigmoidã€tanhã€relu
- è¾“å‡ºå±‚æ ¹æ®ä»»åŠ¡ä¸åŒï¼ŒäºŒåˆ†ç±»é—®é¢˜ä½¿ç”¨sigmoidã€tanhã€reluï¼Œå¤šåˆ†ç±»ä½¿ç”¨softmax

### é˜¶è·ƒå‡½æ•°
- ç†æƒ³æ¿€æ´»å‡½æ•°æ˜¯é˜¶è·ƒå‡½æ•°ï¼Œ0 è¡¨ç¤ºæŠ‘åˆ¶ç¥ç»å…ƒï¼Œè€Œ1è¡¨ç¤ºæ¿€æ´»ç¥ç»å…ƒ
- é˜¶è·ƒå‡½æ•°å…·æœ‰ä¸è¿ç»­ã€ä¸å…‰æ»‘ç­‰ä¸å¥½çš„æ€§è´¨ï¼Œå¸¸ç”¨çš„æ˜¯Sigmoidå‡½æ•°

$$stepfunc(x)=1\;if\;x>0\;else\;0$$

### Sigmoidå‡½æ•°
- Sigmoidå‡½æ•°å¯èƒ½åœ¨è¾ƒå¤§èŒƒå›´å†…å˜åŒ–çš„è¾“å…¥å€¼æŒ¤å‹åˆ°ï¼ˆ0,1ï¼‰è¾“å‡ºå€¼èŒƒå›´å†…ï¼Œå› æ­¤æœ‰æ—¶ä¹Ÿç§°ä¸ºâ€æŒ¤å‹å‡½æ•°â€
- æŠŠè¿™æ ·è®¸å¤šä¸ªç¥ç»å…ƒæŒ‰ä¸€å®šçš„å±‚æ¬¡ç»“æ„è¿æ¥èµ·æ¥ï¼Œå°±å¾—åˆ°äº†ç¥ç»ç½‘ç»œã€‚

![Sigmoidå‡½æ•°](/images/pasted-93.png)

$$sigmoid(x)=\frac{1}{1+e^{-x}}$$

### tanhå‡½æ•°
- tanhå‡½æ•°è¶‹è¿‘0çš„é€Ÿåº¦æ¯”sigmoidæ›´ä¸ºå¿«

$$f(x)=tanh(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$

```py
x = np.linspace(-10,10)
y = np.tanh(x)
```

### ReLuå‡½æ•°

$$relu(x)=max\{0,x\}$$

### Leaky ReLuå‡½æ•°

$$relu(x)=max\{0.1x,x\}$$

### ELUå‡½æ•°

$$\begin{cases}
 x & \text{ if } x>0 \\ \alpha (e^x-1) & \text{ if } x\le0\end{cases}$$

### ReLU6å‡½æ•°

$$relu(x)=min(max\{0,x\},6)$$

### äºŒåˆ†ç±»
- ä½¿ç”¨sigmoidå‡½æ•°ï¼š$\sigma(\omega^Tx+b)=\frac{1}{1+e^{-(\omega^Tx+b)}}$
- æ¡ä»¶æ¦‚ç‡ä¸ºï¼š$p_w(y=1|x)=\sigma(\omega^Tx+b)$ $p_w(y=0|x)=1-\sigma(\omega^Tx+b)$

### å¤šåˆ†ç±»
#### softmax
- å‡è®¾æœ‰ä¸€ä¸ªæ•°ç»„Vï¼Œ$V_i$è¡¨ç¤ºVä¸­çš„ç¬¬iä¸ªå…ƒç´ ï¼Œé‚£ä¹ˆè¿™ä¸ªå…ƒç´ çš„softmaxå€¼ä¸º:
- $S_i=\frac{e^i}{\sum_j{e^j}}$
- æŠŠå¤§èŒƒå›´çš„è¾“å…¥è½¬ä¸º[0,1]èŒƒå›´çš„æ¦‚ç‡å½¢å¼

![softmax](/images/pasted-102.png)

```py
def softmax(x):
    if x.ndim == 2:
        x = x.T
        x = x - np.max(x, axis=0)
        y = np.exp(x) / np.sum(np.exp(x), axis=0)
        return y.T 
    x = x - np.max(x) # é˜²æ­¢xè¿‡å¤§å¯¼è‡´expç»“æœæº¢å‡º
    return np.exp(x) / np.sum(np.exp(x))
```

## æŸå¤±å‡½æ•°
åˆç§°ç›®æ ‡å‡½æ•°(objective function)ï¼Œæˆ–è¯¯å·®å‡½æ•°(error function)ï¼Œæˆ–ä»£ä»·å‡½æ•°ï¼ˆcost functionï¼‰ , æˆ–ç»éªŒé£é™©(empirical risk)ï¼›ç”¨æ¥åº¦é‡ç½‘ç»œå®é™…è¾“å‡ºä¸æœŸæœ›è¾“å‡ºä¹‹é—´çš„ä¸ä¸€è‡´ç¨‹åº¦ï¼ŒæŒ‡å¯¼ç½‘ç»œçš„å‚æ•°å­¦ä¹ å’Œè¡¨ç¤ºå­¦ä¹ ã€‚
### å›å½’é—®é¢˜
- SSEï¼ˆSum of Squared Errorï¼‰å‡æ–¹è¯¯å·®å’Œ
- $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})^2}+\lambda\sum_{j=1}^{n}{\theta^2_j}$

### åˆ†ç±»é—®é¢˜
- CEï¼ˆCross Entropyï¼‰äº¤å‰ç†µï¼Œå¯¹æ•°æŸå¤±
- $J(\theta)=-\frac{1}{m}\sum_{i=1}^{m}{y^{(i)}\ln{h_\theta(x^{(i)})+(1-y^{(i)})\ln{(1-h_\theta(x^{(i)})})}}+\lambda\sum^{n}_{j=1}{\theta^2_j}$

- **ç†µ**ç”¨äºåº¦é‡å˜é‡ä¸ç¡®å®šæ€§çš„ç¨‹åº¦ï¼š$H(X)=-\sum^{n}_{i=1}{p(x_i)\log{p(x_i)}}$ï¼Œè¶Šå¤§è¯´æ˜ä¸ç¡®å®šæ€§è¶Šé«˜

- **äº¤å‰ç†µ**ç”¨äºåº¦é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒé—´çš„å·®å¼‚æ€§ä¿¡æ¯ï¼Œè¶Šç¡®ä¿¡äº¤å‰ç†µè¶Šå°
- è®¾ p(x),q(x) åˆ†åˆ«æ˜¯ç¦»æ•£éšæœºå˜é‡Xçš„ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œå…¶ä¸­p(x)æ˜¯ç›®æ ‡åˆ†å¸ƒï¼Œpå’Œqçš„äº¤å‰ç†µå¯ä»¥çœ‹åšæ˜¯ï¼Œä½¿ç”¨åˆ†å¸ƒq(x) è¡¨ç¤ºç›®æ ‡åˆ†å¸ƒp(x)çš„å›°éš¾ç¨‹åº¦ï¼š$H(p,q)=\sum_i{p(x_i)\log{\frac{1}{\log{q(x_i)}}}}=-\sum_i{p(x_i)\log{q(x_i)}}$

- **äº¤å‰ç†µæŸå¤±**ç”¨äºæè¿°çœŸå®æ¦‚ç‡å’Œæ¨¡å‹é¢„æµ‹æ¦‚ç‡çš„äº¤å‰ç†µ
- softmaxå¾—åˆ°é¢„æµ‹çš„æ¦‚ç‡ä¹‹åï¼ŒæŠŠæ ‡ç­¾è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œå†ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ä¼˜åŒ–æ¨¡å‹ã€‚

- è‹¥$p(y)$ä¸$q(y)$å®Œå…¨åŒ¹é…ï¼Œäº¤å‰ç†µå’Œç†µçš„è®¡ç®—å€¼ç›¸ç­‰ã€‚ä½†å…¶å®äº¤å‰ç†µæ¯”åœ¨çœŸå®åˆ†å¸ƒä¸Šè®¡ç®—å‡ºçš„ç†µå…·æœ‰æ›´å¤§çš„å€¼ï¼Œè¿™ç§å·®å¼‚ç§°ä¸º`Kullback-Leibler Divergence`ã€‚ç®€ç§°KLæ•£åº¦ã€‚åº¦é‡ä¸¤åˆ†å¸ƒçš„å·®å¼‚ï¼š$D_{KL}(P||Q)=-\sum_{x\in X}{p(x)\log{q(x)}}+\sum_{x\in X}{p(x)\log{p(x)}}=H(P,Q)-H(P)$

```py
def cross_entropy_error(y, t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))
```

## æ¢¯åº¦ä¸‹é™æ³•
- æ±‚è§£éçº¿æ€§æ— çº¦æŸä¼˜åŒ–é—®é¢˜çš„åŸºæœ¬æ–¹æ³•
- $w_{i+1}=w_i-a\frac{\partial{J}}{\partial{x}}$
- Jæ˜¯æŸå¤±å‡½æ•°ï¼Œæ²¿è´Ÿæ¢¯åº¦æ–¹å‘è¿­ä»£æ±‚è§£æœ€ä¼˜å‚æ•°ï¼Œaæ˜¯å­¦ä¹ ç‡

### æ‰¹é‡æ¢¯åº¦ä¸‹é™
- (Batch Gradient Descent )åˆ©ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®é›†è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ¥æ‰§è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°
- $\theta\Rightarrow\theta-\eta\cdot\triangledown{J(\theta)}$

- ç¼ºç‚¹ï¼šæ›´æ–°è¾ƒæ…¢ã€ä¸èƒ½åœ¨çº¿æ›´æ–°æ¨¡å‹
- ä¼˜ç‚¹ï¼šå¯¹å‡¹å‡½æ•°å¯å¾—åˆ°å…¨å±€æœ€å°ï¼Œéå‡¸å‡½æ•°å¯æ”¶æ•›åˆ°å±€éƒ¨æå°

### éšæœºæ¢¯åº¦ä¸‹é™
- SGD (Stochastic Gradient Descent)å¯¹æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ç‚¹å’Œæ ‡ç­¾æ‰§è¡Œå‚æ•°æ›´æ–°
- $\theta\Rightarrow\theta-\eta\cdot\triangledown{J(\theta;x^{(i)};y^{(i)})}$
- ç¼ºç‚¹ï¼šæ¢¯åº¦ç²¾åº¦å·®ã€ç›®æ ‡å‡½æ•°ä¸‹é™è¿‡ç¨‹å‡ºç°è¾ƒå¤§æ³¢åŠ¨ã€éš¾ä»¥è·³å‡ºå±€éƒ¨æå°å€¼ç‚¹å’Œéç‚¹
- ä¼˜ç‚¹ï¼šé€Ÿåº¦å¿«ï¼Œå¯åœ¨çº¿å­¦ä¹ 

```py
class SGD:
    def __init__(self, lr=0.01):
        self.lr = lr
    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key] 
```

### å°æ‰¹é‡æ¢¯åº¦ä¸‹é™
- (Mini-batch Gradient Descent)æ¯ğ‘šä¸ªè®­ç»ƒæ ·æœ¬ç‚¹ï¼Œè¿›è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°
- $\theta\Rightarrow\theta-\eta\cdot\triangledown{J(\theta;x^{(i:i+m)};y^{(i:i+m)})}$
- Batch-GDå’Œå•æ ·æœ¬SGDæ–¹æ³•çš„æŠ˜è¡·
- ä¼˜ç‚¹ï¼šå‡å°äº†å‚æ•°æ›´æ–°çš„æ–¹å·®ï¼Œå¯å¹³ç¨³æ”¶æ•›ï¼›é€Ÿåº¦å¿«ï¼Œå¯åˆ©ç”¨ä¼˜åŒ–çš„çŸ©é˜µè¿ç®—åº“æ¥é«˜æ•ˆçš„è®¡ç®—æ¢¯åº¦
- Batchå¤§å°æ ¹æ®é—®é¢˜æ¥å®šã€‚ä¸€èˆ¬è€Œè¨€è®¾ä¸º32ã€ 64ã€ 128æˆ–256å³å¯ã€‚

### æ¢¯åº¦ä¸‹é™æ”¹è¿›ç®—æ³•
#### åŠ¨é‡æ³•Momentum
- åŠ¨é‡æ³•ï¼ŒæŠŠè¿‡å»æ—¶é—´æ­¥éª¤æ›´æ–°çŸ¢é‡çš„ä¸€éƒ¨åˆ†ï¼ˆğ›¾ï¼‰åŠ åˆ°å½“å‰æ›´æ–°çŸ¢é‡
- $v1=\eta\triangledown{J(\theta)}$ $v_k=\gamma v_{k-1}+\eta\triangledown J(\theta{k-1}), \gamma\in(0,1)$ $\theta_k=\theta_{k-1}-v_k$

- åŠ¨é‡é¡¹ğ›¾ ä¸€èˆ¬è®¾ä¸º0.9ã€‚å¯ç†è§£ä¸ºâ€œæ‘©æ“¦â€æ•ˆæœï¼Œé€Ÿåº¦çš„é€æ¸å¢åŠ æ˜¯ä½œä¸ºæ¢¯åº¦çš„ç§»åŠ¨å¹³å‡

```py
class Momentum:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None
    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)
        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] 
            params[key] += self.v[key]
```

#### NAG
- NAGæ˜¯ä¸ºåŠ¨é‡é¡¹æä¾›é¢„çŸ¥èƒ½åŠ›çš„ä¸€ç§æ–¹æ³•ã€‚
- $v_k=\gamma v_{k-1}+\eta\triangledown J(\theta{k-1}-\gamma v_{k-1}), \gamma\in(0,1)$ $\theta_k=\theta_{k-1}-v_k$

![NAG](/images/pasted-104.png)

```py
class Nesterov:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None
    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)
        for key in params.keys():
            self.v[key] *= self.momentum
            self.v[key] -= self.lr * grads[key]
            params[key] += self.momentum * self.momentum * self.v[key]
            params[key] -= (1 + self.momentum) * self.lr * grads[key]
```

#### Adagrad
- Adagradå¯¹ä¸åŒçš„å‚æ•°è°ƒæ•´ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡ï¼Œå­¦ä¹ ç‡è¡°å‡ï¼ˆlearning rate decayï¼‰
  - å¯¹éé¢‘ç¹å‡ºç°ç‰¹å¾ç›¸å…³çš„å‚æ•°æ‰§è¡Œè¾ƒå¤§çš„æ›´æ–°ï¼ˆå³è¾ƒå¤§çš„å­¦ä¹ ç‡ï¼‰
  - å¯¹é¢‘ç¹å‡ºç°ç‰¹å¾ç›¸å…³çš„å‚æ•°æ‰§è¡Œè¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆå³è¾ƒå°çš„å­¦ä¹ ç‡)

- $g_{t,i}=\triangledown J(\theta_{i,t})$ $\theta_{t+1,j}=\theta{t,i}-\frac{\eta}{\sqrt{G_{t,ii}+\varepsilon}}\cdot g_{t,i}$
- ğºğ‘¡æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼Œå…¶æ¯ä¸€ä¸ªå¯¹è§’å…ƒç´ æ˜¯åˆ°æ—¶é—´ğ‘¡çš„æ¢¯åº¦çš„å¹³æ–¹ä¹‹å’Œï¼Œå³$\sum^{t}_{i=1}g^2_i$
- ğœ– æ˜¯ä¸€ä¸ªå¹³æ»‘é¡¹ä»¥é¿å…é™¤ä»¥é›¶(é€šå¸¸å¤§å°ä¸º 1ğ‘’ âˆ’ 8).

- ç¼ºç‚¹ï¼šåˆ†æ¯çš„æ¢¯åº¦å¹³æ–¹é€æ­¥ç´¯è®¡å˜å¤§ï¼Œå¯å¯¼è‡´å­¦ä¹ ç‡ä¸æ–­æ”¶ç¼©ï¼Œæ”¶æ•›å˜æ…¢ï¼Œä»è€Œå¤±å»å­¦ä¹ èƒ½åŠ›

```py
class AdaGrad:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None
    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

#### Adadelta
- Adagradçš„æ”¹è¿›ç‰ˆï¼š
  - è®¡ç®—å†å²æ¢¯åº¦ä¿¡æ¯æ—¶å¼•å…¥æ—¶é—´çª—ï¼Œè€Œéæ‰€æœ‰å†å²æ—¶é—´ï¼ˆå¼•å…¥è¡°å‡å› å­ï¼‰
    - $E[g^2]_t=\gamma E[g^2]_{t-1}+(1-\gamma)g^2$ 
    - $\triangle\theta_{t}=-\frac{\eta}{\sqrt{E[g^2]_t+\varepsilon}}g_t$
    - $\triangle\theta_t=-\frac{\eta}{RMS[g]_t}g_t$ 

  - ç´¯ç§¯å‚æ•°å†å²æ›´æ–°é‡è¿›è¡ŒåŠ é€Ÿ(ç±»ä¼¼äºåŠ¨é‡æ–¹æ³•)ï¼Œç”±Hessianæ–¹æ³•æ¨å¯¼å‡ºä¸€é˜¶è¿‘ä¼¼Hessianæ–¹æ³•
    - $E[\triangle\theta^2]_t=\gamma E[\triangle \theta2]_{t-1}+(1-\gamma)\triangle\theta^2_t$ 
    - $RMS[\triangle\theta]_t=\sqrt{E[\triangle\theta^2]_t+\varepsilon}$


#### RMSprop
- RMSPropæ˜¯ä¸€ä¸ªæœªæ­£å¼å‘è¡¨çš„è‡ªé€‚åº”å­¦ä¹ ç‡æ–¹æ³•ï¼›ç”±Geoff Hintonæå‡º
- $E[g^2]_t=0.9E[g^2]_{t-1}+0.1g^2$ $\theta_{t+1}=\theta_{t}-\frac{1}{\sqrt{E[g^2]_t+\varepsilon}}g_t$ 
- Hintonå»ºè®®ğ›¾ è®¾ä¸º 0.9, å­¦ä¹ ç‡ğœ‚ çš„é»˜è®¤å€¼ä¸º0.001
- RMSPropæ–¹æ³•å¹¶ä¸æ˜¯å°†è¿‡å»æ‰€æœ‰çš„æ¢¯åº¦ä¸€è§†åŒä»åœ°ç›¸åŠ ï¼Œè€Œæ˜¯é€æ¸åœ°é—å¿˜è¿‡å»çš„æ¢¯åº¦ï¼Œåœ¨åšåŠ æ³•è¿ç®—æ—¶å°†æ–°æ¢¯åº¦çš„ä¿¡æ¯æ›´å¤šåœ°åæ˜ å‡ºæ¥ã€‚å³é‡‡ç”¨â€œæŒ‡æ•°ç§»åŠ¨å¹³å‡â€ï¼šæœ€è¿‘ 1/(1 âˆ’ ğ›¾) ä¸ªæ—¶é—´æ­¥çš„å°æ‰¹é‡éšæœºæ¢¯åº¦å¹³æ–¹é¡¹çš„åŠ æƒå¹³å‡ã€‚

```py
class RMSprop:
    def __init__(self, lr=0.01, decay_rate = 0.99):
        self.lr = lr
        self.decay_rate = decay_rate
        self.h = None
    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
        for key in params.keys():
            self.h[key] *= self.decay_rate
            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

#### Adam
- Adamæ˜¯å¦å¤–ä¸€ç§ä¸ºæ¯ä¸€å‚æ•°è®¡ç®—è‡ªé€‚åº”å­¦ä¹ ç‡çš„æ–¹æ³•ï¼Œé™¤äº†åƒAdadeltaå’ŒRMSpropå­˜å‚¨è¿‡å»æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°è¡°å‡å¹³å‡å€¼ğ‘£ğ‘¡, Adamä¹Ÿä¿ç•™äº†è¿‡å»æ¢¯åº¦çš„æŒ‡æ•°è¡°å‡å¹³å‡å€¼ğ‘šğ‘¡, ç±»ä¼¼åŠ¨é‡

- $m_t=\beta_1m_{t-1}+(1-\beta_1)g_t$
- $v_t=\beta_2v_{t-1}+(1-\beta_2)g_t^2$
- ğ‘šğ‘¡ å’Œğ‘£ğ‘¡åˆ†åˆ«æ˜¯ä¸€é˜¶çŸ©(å‡å€¼) å’Œæ¢¯åº¦äºŒé˜¶çŸ©(æœ‰åæ–¹å·®) çš„ä¼°è®¡å€¼ï¼Œå«æœ‰åå·®æ ¡æ­£ï¼ˆbias-correctedï¼‰ çš„ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ© çš„ä¼°è®¡:$\hat{m}_t=\frac{m_t}{1-\beta_1^t}$ $\hat{v}_t=\frac{v_t}{1-\beta_2^t}$
- å‚æ•° ğ›½1ã€ ğ›½2 âˆˆ [0, 1) æ§åˆ¶äº†è¿™äº›ç§»åŠ¨å‡å€¼ï¼ˆmoving averageï¼‰æŒ‡æ•°è¡°å‡ç‡ã€‚
- æ›´æ–°è§„åˆ™$\theta_{t+1}=\theta{t}-\frac{\eta}{\sqrt{\hat{v}_t}+\varepsilon}\hat{m}_t$
- Adam çš„æ ¸å¿ƒåœ¨äºç”¨æŒ‡æ•°æ»‘åŠ¨å¹³å‡å»ä¼°è®¡æ¢¯åº¦æ¯ä¸ªåˆ†é‡çš„ä¸€é˜¶çŸ©(åŠ¨é‡)å’ŒäºŒé˜¶çŸ©(ç”¨äºè‡ªé€‚åº”å­¦ä¹ ç‡)ï¼Œå¹¶ç”¨äºŒé˜¶çŸ©å»å½’ä¸€åŒ–ä¸€é˜¶çŸ©ï¼Œå¾—åˆ°æ¯ä¸€æ­¥çš„æ›´æ–°é‡ã€‚é€šå¸¸è€Œè¨€ï¼Œ Adamæ˜¯è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•çš„è¾ƒä¼˜é€‰æ‹©

```py
class Adam:
    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.v = None
    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)
        self.iter += 1
        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         
        for key in params.keys():
            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])
            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)
```

# è¯¯å·®é€†ä¼ æ’­ç®—æ³•â€”â€”BPç¥ç»ç½‘ç»œ
- è¯¯å·®é€†ä¼ æ’­ï¼ˆerror BackPropagationï¼Œç®€ç§°BPï¼‰å®ƒæ˜¯è¿„ä»Šä¸ºæ­¢æœ€æˆåŠŸçš„ç¥ç»ç½‘ç»œå­¦ä¹ ç®—æ³•ï¼Œç°å®ä»»åŠ¡ä¸­ä½¿ç”¨ç¥ç»ç½‘ç»œæ—¶ï¼Œå¤§å¤šåœ¨ä½¿ç”¨BPç®—æ³•è¿›è¡Œè®­ç»ƒå¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼Œè¿˜å¯ç”¨äºè®­ç»ƒä¾‹å¦‚é€’å½’ç¥ç»ç½‘ç»œã€‚

## é“¾å¼æ³•åˆ™
- $y=g(x)$ï¼Œ$z=h(y)$
  - $$\nabla{x}\rightarrow\nabla{y}\rightarrow\nabla{z}$$ 
  - $$\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$$
- $x=g(s)$ï¼Œ$y=h(s)$ï¼Œ$z=k(x,y)$
  - $$\nabla{s}\rightarrow\nabla{x},\nabla{y}\rightarrow\nabla{z}$$
  - $$\frac{dz}{ds}=\frac{dz}{dx}\frac{dx}{ds}+\frac{dz}{dy}\frac{dy}{ds}$$

## BPç®—æ³•è¿‡ç¨‹
- ç»™å®šè®­ç»ƒé›†ï¼š$D=((x_1,y_1),(x_2,y_2)....(x_m,y_m)),xâˆˆ\Bbb{R}^d,yâˆˆ\Bbb{R}^l,$  
- è¾“å…¥ï¼šdç»´ç‰¹å¾å‘é‡ï¼Œï¼ˆdä¸ªå±æ€§ï¼‰ï¼›  
- è¾“å‡ºï¼šLä¸ªè¾“å‡ºå€¼ï¼ˆlç»´å®å€¼å‘é‡ï¼‰ï¼›  
- éšå±‚ï¼šå‡å®šä½¿ç”¨qä¸ªéšå±‚ç¥ç»å…ƒï¼›  
- è¾“å‡ºå±‚æƒé‡ï¼š$w_{ij}$ï¼›éšå±‚æƒé‡ï¼š$v_{ij}$ï¼›è¾“å‡ºå±‚é˜ˆå€¼ï¼š$Î¸_i$ï¼›éšå±‚é˜ˆå€¼ï¼š$Î³_i$  
- éšå±‚è¾“å…¥$a_h=\sum^{d}_{i=1}{w_{hj}x_i}$
- è¾“å‡ºå±‚è¾“å…¥$\beta_j=\sum^{q}_{h=1}{w_{hj}b_h}$ 
- éšå±‚ç¬¬hä¸ªç¥ç»å…ƒè¾“å‡ºï¼šbhï¼›  
- å‡å®šåŠŸèƒ½å•å…ƒå‡ä½¿ç”¨Sigmoidå‡½æ•° ã€‚

![ç¥ç»ç½‘ç»œå˜é‡å’Œç¬¦å·](/images/pasted-98.png)

- $w_{jk}^l$ï¼Œ`w`ä»£è¡¨æƒé‡ï¼Œ`l`ä»£è¡¨å±‚æ•°ï¼Œ`k`ä»£è¡¨ç¬¬`l-1`å±‚çš„ç¥ç»å…ƒç¼–å·ï¼Œ`j`ä»£è¡¨ç¬¬`l`å±‚ç¥ç»å…ƒç¼–å·

### å‰é¦ˆä¼ æ’­
- å¯¹è®­ç»ƒ$(x_k,y_k)$
- $P_{1}^1=f_1(w_{11}^1x_1+w_{12}^1x_2)$
- $P_{2}^1=f_2(w_{21}^1x_1+w_{22}^1x_2)$
- $P_{3}^1=f_3(w_{31}^1x_1+w_{32}^1x_2)$
- $P_{1}^2=f_4(w_{11}^2P_{1}^1+w_{12}^1P_{2}^1+w_{13}^2P_{3}^1)$
- $P_{2}^2=f_5(w_{21}^2P_{1}^1+w_{22}^1P_{2}^1+w_{23}^2P_{3}^1)$
- è¾“å‡ºä¸ºï¼š$y=f6(w_{11}^3P_1^2+w_{12}^3P_2^2)$

- çŸ©é˜µå½¢å¼ï¼š

$$z^{l+1}_{k\times 1}=w^{l+1}_{k\times j}\cdot a^{l}_{j\times 1}+b^{l+1}_{k\times 1}$$

$$a^{l+1}_{k\times 1}=\sigma(z^{l+1}_{k\times 1})$$

### åå‘ä¼ æ’­
- åˆ™ç½‘ç»œåœ¨$(x_k,y_k)$çš„å‡æ–¹è¯¯å·®ä¸º$E_k=\frac{1}{2}\sum^{l}_{j=1}{(\hat{y}^k_j-y^k_j)^2}$ï¼ŒæœªçŸ¥çš„å‚æ•°åŒ…æ‹¬éšå±‚åŠè¾“å‡ºå±‚æƒå€¼ã€é˜ˆå€¼ã€‚
- BPé€šè¿‡è¿­ä»£å­¦ä¹ ï¼Œåœ¨æ¯ä¸€è½®é‡‡ç”¨å¹¿ä¹‰çš„æ„ŸçŸ¥æœºå­¦ä¹ è§„åˆ’å¯¹å‚æ•°è¿›è¡Œæ›´æ–°ä¼°è®¡ï¼š$v\leftarrow v+\triangle v$ã€‚
- BPç®—æ³•åŸºäºæ¢¯åº¦ä¸‹é™ç­–ç•¥ï¼ˆgradient descentï¼‰ï¼Œä»¥ç›®æ ‡è´Ÿæ¢¯åº¦æ–¹å‘å¯¹å‚æ•°è¿›è¡Œè°ƒæ•´ã€‚å¯¹äºè¯¯å·®Ekï¼Œç»™å®šå­¦ä¹ ç‡ï¼š$\eta \in(0,1)$ï¼Œæ§åˆ¶è¿­ä»£ä¸­çš„æ›´æ–°æ­¥é•¿ï¼Œå¤ªå¤§å®¹æ˜“éœ‡è¡ï¼Œå¤ªå°åˆ™æ”¶æ•›è¿‡æ…¢ã€‚å…¶ä¸­wÎ¸ä¸vÎ³çš„å­¦ä¹ ç‡ä¸ä¸€å®šç›¸ç­‰ã€‚

- æ›´æ–°æƒé‡å…¬å¼ä¸ºï¼š$w_{11}^3=w+\triangle w=w+\eta -\frac{y}{w_{11}^3}$ï¼Œå°†åå·®åå‘ä¼ æ’­ï¼Œè®¡ç®—ä¸»è¦ä»»åŠ¡å°±æ˜¯æ±‚è§£åå¯¼ã€‚

- æŸå¤±å‡½æ•°ä¸º$J(\theta)$ï¼Œç”¨äºè®¡ç®—åå·®
- $\frac{\partial{J}}{\partial w_{11}^3}=\frac{\partial J}{\partial y}\cdot\frac{\partial y}{\partial w_{11}^3}$
- $\frac{\partial{J}}{\partial w_{12}^3}=\frac{\partial J}{\partial y}\cdot\frac{\partial y}{\partial w_{12}^3}$

$$\frac{\partial J}{\partial w_{23}^2}=\frac{\partial J}{\partial y}\frac{\partial y}{\partial P_2^2}\frac{\partial P_2^2}{\partial w_{23}^2}$$

- å…¶ä½™çš„æ¨å¯¼ç±»ä¼¼ï¼Œåˆ©ç”¨é“¾å¼æ³•åˆ™å°†æ¯ä¸ªç¥ç»å…ƒçš„æ±‚å¯¼å€¼ã€è¾“å…¥å€¼éƒ½è®°å½•ä¸‹æ¥ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’çš„æ€æƒ³ï¼Œå¯ä»¥ä½¿æ›´æ–°æƒé‡è®¡ç®—å¤§å¤§åŠ å¿«ã€‚

- çŸ©é˜µå½¢å¼
è¯¯å·®é¡¹-è¾“å‡ºå±‚ï¼š$$\sigma^l_j=\frac{\partial C}{\partial z_j^l}=\frac{\partial C}{\partial a_j^l}\cdot\frac{\partial a_j^l}{\partial z_j^l}=\triangledown_a^C\odot\sigma'(z^l)$$

è¯¯å·®é¡¹-ä¸­é—´å±‚ï¼š$$\sigma^l_j=\frac{\partial C}{\partial z_j^l}=\sum_k{\frac{\partial C}{\partial z_k^{l+1}}\cdot\frac{\partial z_k^{l+1}}{\partial z_k^l}}=\sum_k{\frac{\partial C}{\partial z_k^{l+1}}\cdot\frac{\partial z_k^{l+1}}{\partial a_j^l}\cdot\frac{\partial a_j^l}{\partial z_k^l}}=(w^{l+1}_{j\times k})^T\odot \sigma'(z^l)_{j\times 1}$$

wçŸ©é˜µï¼š$$\frac{\partial C}{\partial w^{l+1}_{kj}}=\frac{\partial C}{\partial z^{l+1}_{k}}\cdot\frac{\partial z^{l+1}_{k}}{\partial w^{l+1}_{kj}}=\sigma^{l+1}_{k}\cdot\frac{\sum_j{w^{l+1}_{kj}a_j^l+b^{l+1}_{k}}}{w^{l+1}_{kj}}=\sigma^{l+1}_{k}\cdot a^{l}_{j}=\sigma^{l+1}_{k}\cdot (a^{l}_{j})^T$$

bçŸ©é˜µï¼š$$\frac{\partial C}{\partial b^{l+1}_{k}}=\sigma^{l+1}_{k}\cdot\frac{\partial z^{l+1}_{k}}{\partial b^{l+1}_{k}}=\sigma^{l+1}_{k}$$

## BPç®—æ³•æµç¨‹
- ç®—æ³•çš„å·¥ä½œæµç¨‹ï¼š

![BPç®—æ³•æµç¨‹](/images/pasted-99.png)

## å¯¼æ•°è®¡ç®—

æ–¹ç¨‹|æ±‚å¯¼
-|-
$f(x)=x$|$f'(x)=1$
$f(x)=0 if\;x<0\;else\;1$|$f'(x)= 0$
$f(x)=sigmoid(x)=\frac{1}{1+e^{-x}}$|$f'(x)=f(x)(1-f(x))$
$f(x)=relu(x)$|$f'(x)=0\;if\;x<0\;else\;1$
$tanh(x)$|$tanh'(x)=1-tanh(x)^2$
$f(x)=softmax(x)=\frac{e^{x_i}}{\sum_{j=1}^{J}{e^{x_j}}}$|$\frac{\partial f_i(x)}{\partial x_j}=f_i(x)(\delta_{ij}-f_j(x))$å…¶ä¸­ï¼š$\delta_{ij}=1\;if\;i==j\;else\;0$

## æ ‡å‡†BPç®—æ³•ä¸ç´¯è®¡BPç®—æ³•
- ä¸»è¦ç›®æ ‡ï¼šæœ€å°åŒ–è®­ç»ƒé›†Dä¸Šçš„ç´¯è®¡è¯¯å·® ã€‚å‰é¢ç®—æ³•æ›´æ–°è§„åˆ™æ˜¯åŸºäºå•ä¸ªEkæ¨å¯¼çš„ï¼Œä¹Ÿç§°ä½œâ€œæ ‡å‡†BPç®—æ³•â€ã€‚è‹¥ä½¿ç”¨åŸºäºç´¯è®¡è¯¯å·®æœ€å°åŒ–çš„æ›´æ–°è§„åˆ™ï¼Œæˆä¸ºç´¯è®¡è¯¯å·®é€†ä¼ æ’­ç®—æ³•ï¼ˆaccumulated errror backpropagationï¼‰ã€‚ä¸¤è€…éƒ½å¾ˆå¸¸ç”¨ï¼š

ç®—æ³•|è¯´æ˜
-|-
æ ‡å‡†BPç®—æ³•|	1ã€æ¯æ¬¡é’ˆå¯¹å•ä¸ªè®­ç»ƒæ ·ä¾‹æ›´æ–°æƒå€¼ä¸é˜ˆå€¼ï¼›<br>2ã€å‚æ•°æ›´æ–°é¢‘ç¹ï¼Œä¸åŒæ ·ä¾‹å¯ä»¥æŠµæ¶ˆï¼Œéœ€è¦å¤šæ¬¡è¿­ä»£
ç´¯è®¡BPç®—æ³•|	1ã€å…¶ä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å°åŒ–æ•´ä¸ªè®­ç»ƒé›†ä¸Šçš„ç´¯è®¡è¯¯å·®ï¼›<br>2ã€è¯»å–æ•´ä¸ªè®­ç»ƒé›†ä¸€éæ‰å¯¹å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œå‚æ•°æ›´æ–°é¢‘ç‡è¾ƒä½

- ç´¯è®¡BPç®—æ³•æ›´æ–°é¢‘ç‡ä½ï¼Œé˜²æ­¢ä¸åŒæ ·ä¾‹å¯¼è‡´è®­ç»ƒå‡ºç°æŠµæ¶ˆçš„ç°è±¡ã€‚åœ¨å¾ˆå¤šä»»åŠ¡ä¸­ï¼Œç´¯è®¡è¯¯å·®ä¸‹é™åˆ°ä¸€å®šç¨‹åº¦åï¼Œè¿›ä¸€æ­¥ä¸‹é™ä¼šéå¸¸ç¼“æ…¢ï¼Œè¿™æ˜¯æ ‡å‡†BPç®—æ³•å¾€å¾€ä¼šè·å¾—è¾ƒå¥½çš„è§£ï¼Œå°¤å…¶å½“è®­ç»ƒé›†éå¸¸å¤§æ—¶æ•ˆæœæ›´æ˜æ˜¾ã€‚

## æ•°æ®é¢„å¤„ç†
- å‡å€¼å½’ä¸€åŒ–(batch normalization)ï¼šéšç€ç½‘ç»œçš„æ·±åº¦å¢åŠ ï¼Œæ¯å±‚ç‰¹å¾å€¼åˆ†å¸ƒä¼šé€æ¸çš„å‘æ¿€æ´»å‡½æ•°çš„è¾“å‡ºåŒºé—´çš„ä¸Šä¸‹ä¸¤ç«¯ï¼ˆæ¿€æ´»å‡½æ•°é¥±å’ŒåŒºé—´ï¼‰é è¿‘ï¼Œè¿™æ ·ç»§ç»­ä¸‹å»å°±ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚BNå°±æ˜¯é€šè¿‡æ–¹æ³•å°†è¯¥å±‚ç‰¹å¾å€¼åˆ†å¸ƒé‡æ–°æ‹‰å›æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œç‰¹å¾å€¼å°†è½åœ¨æ¿€æ´»å‡½æ•°å¯¹äºè¾“å…¥è¾ƒä¸ºæ•æ„Ÿçš„åŒºé—´ï¼Œè¾“å…¥çš„å°å˜åŒ–å¯å¯¼è‡´æŸå¤±å‡½æ•°è¾ƒå¤§çš„å˜åŒ–ï¼Œä½¿å¾—æ¢¯åº¦å˜å¤§ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±ï¼ŒåŒæ—¶ä¹Ÿå¯åŠ å¿«æ”¶æ•›ã€‚

- è¿‡ç¨‹ï¼šinput={x1,x2,x3â€¦xn}
  1. è®¡ç®— x1-xnçš„å‡å€¼u
  2. è®¡ç®—x1-xnçš„æ–¹å·®v
  3. æ¯ä¸ª$x_i = (x_i â€“ u) / (sqrt(v^2)+ e)$ eæ˜¯ä¸€ä¸ªå°å°åç½®ï¼Œé˜²æ­¢åˆ†æ¯è¶‹å‘äº0. 
  4. åœ¨å¯¹ç»“æœè¿›è¡Œscaleäºshiftæ“ä½œ $x_i = scale*x_i + shift$
- ç¬¬å››æ­¥å­˜åœ¨çš„åŸå› æ˜¯batch_normalåï¼Œæ•°æ®è¶‹å‘æ ‡å‡†æ­£æ€ï¼Œä¼šå¯¼è‡´ç½‘ç»œè¡¨è¾¾èƒ½åŠ›å˜å·®ï¼Œè¿™é‡ŒåŠ å…¥åæ ‡å‡†æ­£æ€åˆ†å¸ƒæœ‰äº›åç§»ï¼Œå˜å¾—ä¸é‚£ä¹ˆæ ‡å‡†äº†ã€‚è¿™ä¸¤ä¸ªå‚æ•°æ—¶å­¦ä¹ è€Œæ¥ã€‚

- ä¼˜ç‚¹ï¼šå‡å°‘æ¢¯åº¦æ¶ˆå¤±ï¼ŒåŠ å¿«äº†æ”¶æ•›è¿‡ç¨‹ã€‚èµ·åˆ°ç±»ä¼¼dropoutä¸€æ ·çš„æ­£åˆ™åŒ–èƒ½åŠ›ï¼Œä¸€å®šç¨‹åº¦ä¸Šé˜²æ­¢è¿‡æ‹Ÿåˆã€‚æ”¾å®½äº†ä¸€å®šçš„è°ƒå‚è¦æ±‚ã€‚å¯ä»¥æ›¿ä»£LRNã€‚

- ç¼ºç‚¹ï¼šéœ€è¦è®¡ç®—å‡å€¼ä¸æ–¹å·®ï¼Œä¸é€‚åˆåŠ¨æ€ç½‘ç»œæˆ–è€…RNNã€‚è®¡ç®—å‡å€¼æ–¹å·®ä¾èµ–æ¯æ‰¹æ¬¡ï¼Œå› æ­¤æ•°æ®æœ€å¥½è¶³å¤Ÿæ‰“ä¹±ã€‚

## æ¨¡å‹åˆå§‹åŒ–æ–¹æ³•
- å…¨é›¶åˆå§‹åŒ– ï¼šæ— æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒ
- éšæœºåˆå§‹åŒ–ï¼šä½¿ç”¨å°çš„éšæœºæ•°(é«˜æ–¯åˆ†å¸ƒï¼Œé›¶å‡å€¼ï¼Œ 1e-2æ ‡å‡†å·®)åˆå§‹åŒ–ã€‚å°ç½‘ç»œå¯ä»¥ï¼Œå¯¹äºæ·±åº¦ç½‘ç»œæœ‰é—®é¢˜ ã€‚ç½‘ç»œè¾“å‡ºæ•°æ®åˆ†å¸ƒçš„æ–¹å·®ä¼šéšç€ç¥ç»å…ƒçš„ä¸ªæ•°è€Œæ”¹å˜ã€‚
- Xavieråˆå§‹åŒ–ï¼šä¿è¯å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶æ¯ä¸€å±‚çš„æ–¹å·®ä¸€è‡´ã€‚æ ¹æ®æ¯å±‚çš„è¾“å…¥ä¸ªæ•°å’Œè¾“å‡ºä¸ªæ•°æ¥å†³å®šã€‚å‚æ•°éšæœºåˆå§‹åŒ–çš„åˆ†å¸ƒèŒƒå›´ã€‚é«˜æ–¯åˆ†å¸ƒçš„æƒé‡åˆå§‹åŒ–ä¸ºï¼š é«˜æ–¯åˆ†å¸ƒçš„éšæœºæ•°ä¹˜ä¸Š$\frac{\sqrt{2}}{\sqrt{n_{in}+n_{out}}}$ï¼Œninå’Œ noutåˆ†åˆ«è¡¨ç¤ºè¯¥å±‚è¾“å…¥å’Œè¾“å‡ºçš„å‚æ•°ï¼ˆæƒé‡ï¼‰ä¸ªæ•°ã€‚åœ¨tanhæ¿€æ´»å‡½æ•°ä¸Šæœ‰å¾ˆå¥½çš„æ•ˆæœï¼Œä½†ä¸é€‚ç”¨äºReLUæ¿€æ´»å‡½æ•°ã€‚
- Heå‚æ•°åˆå§‹åŒ–ï¼šå¯¹Xavieræ–¹æ³•çš„æ”¹è¿›ï¼Œå°†ReLUéçº¿æ€§æ˜ å°„é€ æˆçš„å½±å“è€ƒè™‘è¿›å‚æ•°åˆå§‹åŒ–ä¸­ã€‚é«˜æ–¯åˆ†å¸ƒçš„æƒé‡åˆå§‹åŒ–ä¸ºï¼š é«˜æ–¯åˆ†å¸ƒçš„éšæœºæ•°ä¹˜ä¸Š$\frac{\sqrt{2}}{\sqrt{n_{in}}}$
- ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œåç½®è®¾ä¸º0

```py
w = np.random.randn(node_num, node_num) * 1 # gauss
w = np.random.randn(node_num, node_num) * 0.01 # gauss fix mu
w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num) # Xavier
w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num) # He
```

## è¶…å‚æ•°è®¾å®š
- è¶…å‚æ•°åŒ…æ‹¬ï¼šç½‘ç»œæ¨¡å‹ï¼ˆç»“æ„ã€å±‚æ•°ã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰ã€å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ã€è¿­ä»£æ¬¡æ•° ï¼ˆepoch, iterationï¼‰ã€ä¼˜åŒ–å™¨
- é€šè¿‡äº¤å‰éªŒè¯æ–¹æ³•è°ƒæ•´è¶…å‚ï¼Œå°†è®­ç»ƒæ•°æ®é›†åˆ†ä¸ºï¼šæ•°æ®é›†+éªŒè¯é›†ï¼Œé€šè¿‡éªŒè¯é›†ç»“æœæ¥è°ƒæ•´è¶…å‚ã€‚åˆ’åˆ†æ–¹æ³•åˆ†ä¸ºï¼šhold-outï¼Œk-fold

## ç¼“è§£è¿‡æ‹Ÿåˆ
- ä¸»è¦ç­–ç•¥

### **æ—©åœearly stopping**ï¼š
- å°†è®­ç»ƒæ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚è®­ç»ƒé›†è®¡ç®—æ¢¯åº¦å’Œæ›´æ–°ï¼ŒéªŒè¯ä¼°è®¡è¯¯å·®ã€‚
  1. è‹¥è®­ç»ƒè¯¯å·®è¿ç»­aè½®çš„å˜åŒ–å°äºb,åˆ™åœæ­¢è®­ç»ƒ
  2. ä½¿ç”¨éªŒè¯é›†ï¼šè‹¥è®­ç»ƒè¯¯å·®é™ä½ï¼ŒéªŒè¯è¯¯å·®å‡é«˜ï¼Œåˆ™åœæ­¢è®­ç»ƒã€‚
- è¿”å›å…·æœ‰æœ€å°éªŒè¯è¯¯å·®çš„é“¾æ¥æƒé‡å’Œé˜ˆå€¼ã€‚

### dropout
- dropoutå¯ä»¥çœ‹åšæ˜¯ä¸€ç§é›†æˆå­¦ä¹ çš„æ–¹å¼ã€‚é€šè¿‡éšæœºå¤±æ´»ç¥ç»å…ƒï¼Œå°†ä¸åŒç½‘ç»œåˆ†åˆ«è®­ç»ƒï¼Œå†è¿›è¡Œç»“åˆã€‚
- è®­ç»ƒé˜¶æ®µï¼šä»¥æ¦‚ç‡ğ‘éšæœºç§»é™¤ç½‘ç»œä¸­çš„ç¥ç»å…ƒç»“ç‚¹ä»¥åŠä¸ä¹‹ç›¸è¿çš„æ‰€æœ‰è¾“å…¥å’Œè¾“å‡ºè¾¹
- æµ‹è¯•é˜¶æ®µ: æ‰€æœ‰ç¥ç»å…ƒå¤„äºæ¿€æ´»æ€ï¼Œä½†ç”¨ç³»æ•°(1 âˆ’ ğ‘) å‡å°‘æ¿€æ´»å€¼æ¥è¡¥å¿è®­ç»ƒæ—¶ä¸¢å¼ƒçš„æ¿€æ´»

```py
class Dropout:
    def __init__(self, dropout_ratio=0.5):
        self.dropout_ratio = dropout_ratio
        self.mask = None
    def forward(self, x, train_flg=True):
        if train_flg: # è®­ç»ƒé˜¶æ®µ
            self.mask = np.random.rand(*x.shape) > self.dropout_ratio
            return x * self.mask
        else:  # æµ‹è¯•é˜¶æ®µ
            return x * (1.0 - self.dropout_ratio)
    def backward(self, dout):
        return dout * self.mask
```

### æ­£åˆ™åŒ–
- regularizationåœ¨è¯¯å·®ç›®æ ‡å‡½æ•°ä¸­ï¼Œå¢åŠ ä¸€é¡¹æè¿°ç½‘ç»œå¤æ‚åº¦ï¼šä¾‹å¦‚è¿æ¥æƒå’Œé˜ˆå€¼çš„å¹³æ–¹å’Œ
- è¯¯å·®ç›®æ ‡å‡½æ•°å¢åŠ æ­£åˆ™åŒ–é¡¹ï¼Œç”¨äºå¯¹ç»éªŒè¯¯å·®å’Œç½‘ç»œå¤æ‚åº¦è¿›è¡ŒæŠ˜ä¸­ã€‚åå¥½æ¯”è¾ƒå°çš„è¿æ¥æƒå’Œé˜ˆå€¼ï¼Œä½¿ç½‘ç»œè¾“å‡ºæ›´â€œå…‰æ»‘â€
- l2èŒƒæ•°æ­£åˆ™åŒ–ï¼š$J(\theta)=J(\theta)+\frac{\lambda}{2m}\sum{\left \| w \right \|  }^2$ï¼Œ$lambda$æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼Œl2æ­£åˆ™åŒ–ä¹Ÿå«åšæƒé‡è¡°å‡
- l1èŒƒæ•°æ­£åˆ™åŒ–ï¼š$J(\theta)=J(\theta)+\frac{\lambda}{2m}\sum{\left \| w \right \|  }$


## å…¨å±€æœ€å°ä¸å±€éƒ¨æå°
 
![æœ€å°ä¸æå°](/images/pasted-100.png)

- ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹å¯çœ‹ä½œä¸€ä¸ªå‚æ•°å¯»ä¼˜è¿‡ç¨‹ï¼šåœ¨å‚æ•°ç©ºé—´ä¸­ï¼Œå¯»æ‰¾ä¸€ç»„æœ€ä¼˜å‚æ•°ä½¿å¾—è¯¯å·®æœ€å°
- ç‰¹ç‚¹ï¼šå­˜åœ¨å¤šä¸ªâ€œå±€éƒ¨æå°â€ï¼›åªæœ‰ä¸€ä¸ªâ€œå…¨å±€æœ€å°â€

- å¸¸ç”¨ç­–ç•¥è·³å‡ºå±€éƒ¨æå°
  - ä¸åŒå‚æ•°è¿›è¡Œåˆå§‹åŒ–	
  - æ¨¡æ‹Ÿé€€ç«ï¼ˆsimulated annealingï¼‰	ä»¥ä¸€å®šæ¦‚ç‡æ¥æ”¶æ¯”å½“å‰è§£æ›´å·®çš„ç»“æœï¼Œæ¯éƒ¨è¿­ä»£ä¸­ï¼Œæ¥å—æ¬¡ä¼˜è§£çš„æ¦‚ç‡éšæ—¶é—´æ¨ç§»è€Œé™ä½ã€‚
  - éšæœºæ¢¯åº¦ä¸‹é™	è®¡ç®—æ¢¯åº¦æ—¶å¢åŠ éšæœºå› ç´ ï¼Œå³ä½¿é™·å…¥å±€éƒ¨æå°ä¹Ÿæœ‰æœºä¼šè·³å‡ºç»§ç»­æœç´¢ã€‚
  - é—ä¼ ç®—æ³•ï¼ˆgenetic algorithmsï¼‰	

# å…¶ä»–å¸¸è§ç¥ç»ç½‘ç»œæ¨¡å‹
## RBFç½‘ç»œ
- RBFï¼ˆRadial Basis Functionï¼Œå¾„å‘åŸºå‡½æ•°ï¼‰ç½‘ç»œåœ¨åˆ†ç±»ä»»åŠ¡ä¸­é™¤BPä¹‹å¤–æœ€å¸¸ç”¨çš„ä¸€ç§

### å•éšå±‚å‰é¦ˆç¥ç»ç½‘ç»œ
- 	ä½¿ç”¨å¾„å‘åŸºå‡½æ•°ä½œä¸ºéšå±‚ç¥ç»å…ƒæ¿€æ´»å‡½æ•°Ïï¼š ï¼Œå®šä¹‰ä¸ºæ ·æœ¬xåˆ°æ•°æ®ä¸­å¿ƒciä¹‹é—´æ¬§å¼è·ç¦»çš„å•è°ƒå‡½æ•°ï¼Œå¸¸ç”¨é«˜æ–¯å¾„å‘åŸºå‡½æ•°ã€‚ ã€‚ciè¡¨ç¤ºéšå±‚ç¥ç»å…ƒå¯¹åº”çš„ä¸­å¿ƒã€wiè¡¨ç¤ºæƒé‡ã€‚
-	è¾“å‡ºå±‚æ˜¯éšå±‚ç¥ç»å…ƒè¾“å‡ºçš„çº¿æ€§ç»„åˆ
### è®­ç»ƒRBFç½‘ç»œï¼š
-	ç¡®å®šç¥ç»å…ƒä¸­å¿ƒciï¼Œå¸¸ç”¨çš„æ–¹å¼åŒ…æ‹¬éšæœºé‡‡æ ·ã€èšç±»ç­‰
-	åˆ©ç”¨BPç®—æ³•ç­‰ç¡®å®šå‚æ•°wiå’ŒÎ²iã€‚

## ARTç½‘ç»œ
- ARTï¼ˆAdaptive Resonance Theoryï¼Œè‡ªé€‚åº”è°æŒ¯ç†è®ºï¼‰ç«äº‰å­¦ä¹ çš„ä»£è¡¨ï¼Œæ˜¯ä¸€ç§å¸¸ç”¨çš„æ— ç›‘ç£å­¦ä¹ ç­–ç•¥ã€‚è¯¥ç­–ç•¥ç½‘ç»œè¾“å‡ºç¥ç»å…ƒç›¸äº’ç«äº‰ï¼Œæ¯ä¸€æ—¶åˆ»ä»…æœ‰ä¸€ä¸ªç«äº‰è·èƒœçš„ç¥ç»å…ƒè¢«æ¿€æ´»ã€‚å…¶ä»–ç¥ç»å…ƒè¢«æŠ‘åˆ¶ã€‚åŒ…å«æ¯”è¾ƒå±‚ã€è¯†åˆ«å±‚ã€è¯†åˆ«é˜ˆå€¼å’Œé‡ç½®æ¨¡å—ã€‚

## SOMç½‘ç»œ 
- SOMï¼ˆSelf-Organizing Mapï¼Œè‡ªç»„ç»‡æ˜ å°„ï¼‰ç½‘ç»œæ˜¯æœ€å¸¸ç”¨çš„èšç±»æ–¹æ³•ä¹‹ä¸€ï¼š 
  -	ç«äº‰å‹çš„æ— ç›‘ç£ç¥ç»ç½‘ç»œ
  -	å°†é«˜ç»´æ•°æ®æ˜ å°„åˆ°ä½ç»´ç©ºé—´ï¼Œå¹¶ä¿æŒè¾“å…¥æ•°æ®åœ¨é«˜ç»´ç©ºé—´çš„æ‹“æ‰‘ç»“æ„ã€‚å³å°†é«˜ç»´ç©ºé—´ä¸­ç›¸ä¼¼çš„æ ·æœ¬ç‚¹æ˜ å°„åˆ°ç½‘ç»œè¾“å‡ºå±‚ä¸­é‚»è¿‘ç¥ç»å…ƒ
  -	æ¯ä¸ªç¥ç»å…ƒæ‹¥æœ‰ä¸€ä¸ªæƒå‘é‡
  -	ç›®æ ‡ï¼šä¸ºæ¯ä¸ªè¾“å‡ºå±‚ç¥ç»å…ƒæ‰¾åˆ°åˆé€‚çš„æƒå‘é‡ä»¥ä¿æŒæ‹“æ‰‘ç»“æ„
- è®­ç»ƒ
  -	ç½‘ç»œæ¥æ”¶è¾“å…¥æ ·æœ¬åï¼Œå°†ä¼šç¡®å®šè¾“å‡ºå±‚çš„â€œè·èƒœâ€ç¥ç»å…ƒï¼ˆâ€œèƒœè€…é€šåƒâ€ï¼‰
  -	è·èƒœç¥ç»å…ƒçš„æƒå‘é‡å°†å‘å½“å‰è¾“å…¥æ ·æœ¬ç§»åŠ¨

## çº§è”ç›¸å…³ç½‘ç»œï¼šâ€œæ„é€ æ€§â€ç¥ç»ç½‘ç»œçš„ä»£è¡¨ 
- æ„é€ æ€§ç¥ç»ç½‘ç»œï¼šå°†ç½‘ç»œç»“æ„ä¹Ÿå½“åšå­¦ä¹ çš„ç›®æ ‡ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰¾åˆ°æœ€ç¬¦åˆçš„ç½‘ç»œç»“æ„ã€‚æ˜¯ç»“æ„è‡ªé€‚åº”ç½‘ç»œçš„é‡è¦ä»£è¡¨ã€‚
- è®­ç»ƒ
  -	å¼€å§‹æ—¶åªæœ‰è¾“å…¥å±‚å’Œè¾“å‡ºå±‚
  -	çº§è”ï¼ˆCascadeï¼‰ï¼šæ–°çš„éšå±‚èŠ‚ç‚¹é€æ¸åŠ å…¥ï¼Œä»è€Œåˆ›å»ºèµ·å±‚çº§ç»“æ„
  -	ç›¸å…³ï¼ˆCorrelationï¼‰ï¼šæœ€å¤§åŒ–æ–°èŠ‚ç‚¹çš„è¾“å‡ºä¸ç½‘ç»œè¯¯å·®ä¹‹é—´çš„ç›¸å…³æ€§

## Elmanç½‘ç»œï¼šé€’å½’ç¥ç»ç½‘ç»œçš„ä»£è¡¨ 
-	ç½‘ç»œå¯ä»¥æœ‰ç¯å½¢ç»“æ„ï¼Œå¯è®©ä½¿ä¸€äº›ç¥ç»å…ƒçš„è¾“å‡ºåé¦ˆå›æ¥æœ€ä¸ºè¾“å…¥
- t æ—¶åˆ»ç½‘ç»œçš„è¾“å‡ºçŠ¶æ€ï¼š ç”± t æ—¶åˆ»çš„è¾“å…¥çŠ¶æ€å’Œ t-1æ—¶åˆ»çš„ç½‘ç»œçŠ¶æ€å…±åŒå†³å®š
- Elmanç½‘ç»œæ˜¯æœ€å¸¸ç”¨çš„é€’å½’ç¥ç»ç½‘ç»œä¹‹ä¸€ 
-	ç»“æ„ä¸å‰é¦ˆç¥ç»ç½‘ç»œå¾ˆç›¸ä¼¼ï¼Œä½†éšå±‚ç¥ç»å…ƒçš„è¾“å‡ºè¢«åé¦ˆå›æ¥
-	ä½¿ç”¨æ¨å¹¿çš„BPç®—æ³•è®­ç»ƒ

## Bolyzmannæœºï¼šâ€åŸºäºèƒ½é‡çš„æ¨¡å‹â€çš„ä»£è¡¨
 
# æ·±åº¦å­¦ä¹ 
## å·ç§¯ç¥ç»ç½‘ç»œCNN
 
![æ·±åº¦å­¦ä¹ ](/images/pasted-101.png)

-	æ¯ä¸ªå·ç§¯å±‚åŒ…å«å¤šä¸ªç‰¹å¾æ˜ å°„ï¼Œæ¯ä¸ªç‰¹å¾æ˜ å°„æ˜¯ä¸€ä¸ªç”±å¤šä¸ªç¥ç»å…ƒæ„æˆçš„â€œå¹³é¢â€ï¼Œé€šè¿‡ä¸€ç§å·ç§¯æ»¤æ³¢å™¨æå–è¾“å…¥çš„ä¸€ç§ç‰¹å¾
-	é‡‡æ ·å±‚äº¦ç§°â€œæ±‡åˆå±‚â€ï¼Œå…¶ä½œç”¨æ˜¯åŸºäºå±€éƒ¨ç›¸å…³æ€§åŸç†è¿›è¡Œäºšé‡‡æ ·ï¼Œä»è€Œåœ¨å‡å°‘æ•°æ®é‡çš„åŒäº‹ä¿ç•™æœ‰ç”¨ä¿¡æ¯
-	è¿æ¥å±‚å°±æ˜¯ä¼ ç»Ÿç¥ç»ç½‘ç»œå¯¹éšå±‚ä¸è¾“å‡ºå±‚çš„å…¨è¿æ¥

- å…¸å‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å°±æ˜¯å¾ˆæ·±å±‚çš„ç¥ç»ç½‘ç»œ